#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JSONæ•°æ®è½¬CSVè„šæœ¬ - å®¤å†…æœºå™¨äººå¯¼èˆªæ•°æ®é›†
å°†Kaggleä¸‹è½½çš„JSONæ ¼å¼æ•°æ®è½¬æ¢ä¸ºé€‚åˆåˆ†æçš„CSVæ ¼å¼

è¾“å…¥: data/archive/outputs/*.json å’Œ data/archive/outputs_2/*.json
è¾“å‡º: data/sensor_readings_2.csv
"""

import json
import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

def extract_features_from_json(json_file):
    """
    ä»å•ä¸ªJSONæ–‡ä»¶ä¸­æå–ç‰¹å¾

    å‚æ•°:
        json_file: JSONæ–‡ä»¶è·¯å¾„

    è¿”å›:
        list: æ¯æ¡è®°å½•çš„ç‰¹å¾å­—å…¸åˆ—è¡¨
    """
    try:
        with open(json_file, 'r') as f:
            data = json.load(f)

        records = []

        # éå†æ¯æ¡è®°å½•
        for record in data.get('data', []):
            feature_dict = {}

            # 1. åŸºç¡€ä¿¡æ¯
            feature_dict['direction'] = record.get('direction', 'unknown')
            feature_dict['brake'] = record.get('brake', 0)
            feature_dict['horn'] = record.get('horn', 0)

            # 2. ä½ç½®ä¿¡æ¯
            pose = record.get('pose', {})
            feature_dict['x'] = pose.get('x', 0)
            feature_dict['y'] = pose.get('y', 0)
            feature_dict['theta'] = pose.get('theta', 0)

            # 3. è·ç¦»ä¼ æ„Ÿå™¨æ•°æ®ç»Ÿè®¡ç‰¹å¾
            dists = record.get('dists', [])
            if dists:
                feature_dict['dist_mean'] = np.mean(dists)
                feature_dict['dist_std'] = np.std(dists)
                feature_dict['dist_min'] = np.min(dists)
                feature_dict['dist_max'] = np.max(dists)
                feature_dict['dist_median'] = np.median(dists)
                feature_dict['dist_q25'] = np.percentile(dists, 25)
                feature_dict['dist_q75'] = np.percentile(dists, 75)
                feature_dict['dist_range'] = np.max(dists) - np.min(dists)
                feature_dict['dist_iqr'] = np.percentile(dists, 75) - np.percentile(dists, 25)

                # åˆ†åŒºç»Ÿè®¡ï¼ˆå‰ã€å·¦ã€å³ã€åï¼‰
                n = len(dists)
                front = dists[:n//4]
                left = dists[n//4:n//2]
                right = dists[n//2:3*n//4]
                back = dists[3*n//4:]

                feature_dict['dist_front_mean'] = np.mean(front) if front else 0
                feature_dict['dist_left_mean'] = np.mean(left) if left else 0
                feature_dict['dist_right_mean'] = np.mean(right) if right else 0
                feature_dict['dist_back_mean'] = np.mean(back) if back else 0

                feature_dict['dist_front_min'] = np.min(front) if front else 0
                feature_dict['dist_left_min'] = np.min(left) if left else 0
                feature_dict['dist_right_min'] = np.min(right) if right else 0
                feature_dict['dist_back_min'] = np.min(back) if back else 0
            else:
                # å¦‚æœæ²¡æœ‰è·ç¦»æ•°æ®,å¡«å……0
                for key in ['dist_mean', 'dist_std', 'dist_min', 'dist_max', 'dist_median',
                           'dist_q25', 'dist_q75', 'dist_range', 'dist_iqr',
                           'dist_front_mean', 'dist_left_mean', 'dist_right_mean', 'dist_back_mean',
                           'dist_front_min', 'dist_left_min', 'dist_right_min', 'dist_back_min']:
                    feature_dict[key] = 0

            # 4. è§’åº¦ä¼ æ„Ÿå™¨æ•°æ®ç»Ÿè®¡ç‰¹å¾
            angles = record.get('angles', [])
            if angles:
                feature_dict['angle_mean'] = np.mean(angles)
                feature_dict['angle_std'] = np.std(angles)
                feature_dict['angle_min'] = np.min(angles)
                feature_dict['angle_max'] = np.max(angles)
                feature_dict['angle_range'] = np.max(angles) - np.min(angles)
            else:
                for key in ['angle_mean', 'angle_std', 'angle_min', 'angle_max', 'angle_range']:
                    feature_dict[key] = 0

            # 5. è®¡æ•°å™¨
            feature_dict['counts_left'] = record.get('counts_left', 0)
            feature_dict['counts_right'] = record.get('counts_right', 0)

            # 6. æ–‡ä»¶åä½œä¸ºIDï¼ˆç”¨äºåŒºåˆ†ä¸åŒåœ°é¢ï¼‰
            file_id = Path(json_file).stem
            feature_dict['file_id'] = file_id

            records.append(feature_dict)

        return records

    except Exception as e:
        print(f"å¤„ç†æ–‡ä»¶ {json_file} æ—¶å‡ºé”™: {e}")
        return []


def determine_surface_type(file_id):
    """
    æ ¹æ®æ–‡ä»¶IDåˆ¤æ–­åœ°é¢ç±»å‹

    æ ¹æ®Kaggleæ•°æ®é›†è¯´æ˜:
    - outputsæ–‡ä»¶å¤¹: å¹³æ»‘è¡¨é¢ (smooth surface)
    - outputs_2æ–‡ä»¶ï¿½ï¿½: ç²—ç³™è¡¨é¢ (rough surface)

    å‚æ•°:
        file_id: æ–‡ä»¶ç¼–å·

    è¿”å›:
        str: 'smooth' æˆ– 'rough'
    """
    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®é›†çš„ç»„ç»‡æ–¹å¼æ¥åˆ¤æ–­
    # æš‚æ—¶è¿”å›unknown,åç»­æ ¹æ®æ–‡ä»¶å¤¹è·¯å¾„åˆ¤æ–­
    return 'unknown'


def main():
    """ä¸»å‡½æ•°:å¤„ç†æ‰€æœ‰JSONæ–‡ä»¶å¹¶åˆå¹¶ä¸ºCSV"""

    print("="*80)
    print("å®¤å†…æœºå™¨äººå¯¼èˆªæ•°æ®é›† - JSONåˆ°CSVè½¬æ¢å·¥å…·")
    print("="*80)

    # è®¾ç½®è·¯å¾„
    base_dir = Path(__file__).parent.parent
    data_dir = base_dir / 'data' / 'archive'
    output_file = base_dir / 'data' / 'sensor_readings_2.csv'

    # æŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
    outputs_dir = data_dir / 'outputs'
    outputs_2_dir = data_dir / 'outputs_2'

    json_files_smooth = list(outputs_dir.glob('*.json')) if outputs_dir.exists() else []
    json_files_rough = list(outputs_2_dir.glob('*.json')) if outputs_2_dir.exists() else []

    print(f"\nğŸ“‚ æ•°æ®æ–‡ä»¶ç»Ÿè®¡:")
    print(f"  - å¹³æ»‘è¡¨é¢æ•°æ® (outputs): {len(json_files_smooth)} ä¸ªæ–‡ä»¶")
    print(f"  - ç²—ç³™è¡¨é¢æ•°æ® (outputs_2): {len(json_files_rough)} ä¸ªæ–‡ä»¶")
    print(f"  - æ€»è®¡: {len(json_files_smooth) + len(json_files_rough)} ä¸ªæ–‡ä»¶")

    if not json_files_smooth and not json_files_rough:
        print("\nâŒ é”™è¯¯: æœªæ‰¾åˆ°JSONæ•°æ®æ–‡ä»¶!")
        print(f"   è¯·æ£€æŸ¥è·¯å¾„: {data_dir}")
        return

    # å¤„ç†æ‰€æœ‰æ–‡ä»¶
    all_records = []

    print("\nğŸ”„ å¤„ç†å¹³æ»‘è¡¨é¢æ•°æ®...")
    for i, json_file in enumerate(json_files_smooth, 1):
        if i % 20 == 0 or i == len(json_files_smooth):
            print(f"  è¿›åº¦: {i}/{len(json_files_smooth)}")
        records = extract_features_from_json(json_file)
        for record in records:
            record['surface'] = 'smooth'  # æ ‡è®°ä¸ºå¹³æ»‘è¡¨é¢
        all_records.extend(records)

    print("ğŸ”„ å¤„ç†ç²—ç³™è¡¨é¢æ•°æ®...")
    for i, json_file in enumerate(json_files_rough, 1):
        if i % 20 == 0 or i == len(json_files_rough):
            print(f"  è¿›åº¦: {i}/{len(json_files_rough)}")
        records = extract_features_from_json(json_file)
        for record in records:
            record['surface'] = 'rough'  # æ ‡è®°ä¸ºç²—ç³™è¡¨é¢
        all_records.extend(records)

    # è½¬æ¢ä¸ºDataFrame
    print("\nğŸ“Š ç”ŸæˆDataFrame...")
    df = pd.DataFrame(all_records)

    # æ•°æ®ç»Ÿè®¡
    print(f"\nâœ… æ•°æ®å¤„ç†å®Œæˆ!")
    print(f"  - æ€»è®°å½•æ•°: {len(df):,}")
    print(f"  - ç‰¹å¾æ•°é‡: {len(df.columns)}")
    print(f"\nğŸ“‹ ç‰¹å¾åˆ—è¡¨:")
    for i, col in enumerate(df.columns, 1):
        print(f"  {i:2d}. {col}")

    print(f"\nğŸ·ï¸  åœ°é¢ç±»å‹åˆ†å¸ƒ:")
    print(df['surface'].value_counts())
    print(f"\næ¯”ä¾‹:")
    print(df['surface'].value_counts(normalize=True))

    # ä¿å­˜CSV
    print(f"\nğŸ’¾ ä¿å­˜CSVæ–‡ä»¶åˆ°: {output_file}")
    output_file.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(output_file, index=False, encoding='utf-8')

    # æ•°æ®è´¨é‡æ£€æŸ¥
    print(f"\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
    print(f"  - ç¼ºå¤±å€¼æ€»æ•°: {df.isnull().sum().sum()}")
    print(f"  - é‡å¤è¡Œæ•°: {df.duplicated().sum()}")

    if df.isnull().sum().sum() > 0:
        print("\nâš ï¸  å­˜åœ¨ç¼ºå¤±å€¼çš„åˆ—:")
        missing = df.isnull().sum()
        missing = missing[missing > 0].sort_values(ascending=False)
        for col, count in missing.items():
            print(f"    - {col}: {count} ({count/len(df)*100:.2f}%)")

    print(f"\nğŸ“ˆ æ•°å€¼ç‰¹å¾ç»Ÿè®¡æ‘˜è¦:")
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    print(df[numeric_cols].describe().round(3))

    print("\n" + "="*80)
    print("âœ… è½¬æ¢å®Œæˆ! ç°åœ¨å¯ä»¥è¿è¡Œ Jupyter Notebook è¿›è¡Œåˆ†æäº†")
    print("="*80)
    print(f"\nä¸‹ä¸€æ­¥:")
    print(f"  1. æ£€æŸ¥ç”Ÿæˆçš„CSVæ–‡ä»¶: {output_file}")
    print(f"  2. è¿è¡Œå‘½ä»¤: cd code && jupyter notebook robot_navigation_analysis.ipynb")


if __name__ == '__main__':
    main()
